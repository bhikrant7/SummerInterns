{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6824ba48-eab2-41d0-bd06-3c00b76b1b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Branch               Cepo  Program  End term exam SGPA - 1st semester   \\\n",
      "0    CSE  Currently enrolled  B.Tech                                 6.5   \n",
      "\n",
      "   End term exam SGPA - 2nd semester  End term exam SGPA - 3rd semester  \\\n",
      "0                                7.2                                6.1   \n",
      "\n",
      "   End term exam SGPA - 4th semester  End term exam SGPA - 5th semester  \\\n",
      "0                                8.2                                6.8   \n",
      "\n",
      "   End term exam SGPA - 6th semester  End term exam SGPA - 7th semester  ...  \\\n",
      "0                                6.6                                6.3  ...   \n",
      "\n",
      "   EDU_LN  SCHL_RCV  URB_RUR INT_CONN How many hrs you study after school?  \\\n",
      "0     Yes        No    Urban     Good                                    1   \n",
      "\n",
      "   How many value added program you have entered? (coursera/ AWS/IBM etc)  \\\n",
      "0                                                  2                        \n",
      "\n",
      "   SPOR_PSN  COC_PART COC_PART_ROLE Cam_plc  \n",
      "0       Yes       yes   Team leader     Yes  \n",
      "\n",
      "[1 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "file_path = '/home/bhikrant07/Desktop/AI/KU_STUDENT_DATA_ON_CAMPUS_PLACEMENT.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "print(data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da58c58-5c61-44ec-a2c2-456a25b7b7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhikrant07/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Convert all text in object columns to lowercase\n",
    "data = data.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
    "encoder = OneHotEncoder(sparse=False,drop ='first')\n",
    "encoded_categorical_data = encoder.fit_transform(data[categorical_features])\n",
    "\n",
    "\n",
    "# Normalize numerical features\n",
    "numerical_features = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "scaler = StandardScaler()\n",
    "scaled_numerical_data = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "# Combine encoded and scaled data\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical_data, columns=encoder.get_feature_names_out(categorical_features))\n",
    "scaled_numerical_df = pd.DataFrame(scaled_numerical_data, columns=numerical_features)\n",
    "processed_data = pd.concat([encoded_categorical_df, scaled_numerical_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea6f7256-29f7-4b61-8f61-d81d61249905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Branch_cse  Branch_ece  Branch_ee  Branch_me  Branch_mscit  \\\n",
      "0         1.0         0.0        0.0        0.0           0.0   \n",
      "\n",
      "   Cepo _passed out  Program_mscit  C_X_B_state board  C_XII_B_state board  \\\n",
      "0               0.0            0.0                1.0                  1.0   \n",
      "\n",
      "   M_F_male  ...  End term exam SGPA - 6th semester  \\\n",
      "0       1.0  ...                           -0.93521   \n",
      "\n",
      "   End term exam SGPA - 7th semester  End term exam SGPA - 8th semester  \\\n",
      "0                          -0.674564                          -0.704771   \n",
      "\n",
      "   CGPA after 8th semester  Class X grade  Class XII grade  \\\n",
      "0                -0.759161       0.222934        -0.335895   \n",
      "\n",
      "   Overall Attendance percentage  Number of internships during undergraduate.  \\\n",
      "0                       0.158114                                     0.192524   \n",
      "\n",
      "   How many hrs you study after school?  \\\n",
      "0                             -0.774139   \n",
      "\n",
      "   How many value added program you have entered? (coursera/ AWS/IBM etc)  \n",
      "0                                          -0.769538                       \n",
      "\n",
      "[1 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print(processed_data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31bef0fc-a99e-4ef4-b4c5-eae79d96fda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Branch_cse', 'Branch_ece', 'Branch_ee', 'Branch_me', 'Branch_mscit',\n",
      "       'Cepo _passed out', 'Program_mscit', 'C_X_B_state board',\n",
      "       'C_XII_B_state board', 'M_F_male', 'C_HLTH_good', 'C_HLTH_poor',\n",
      "       'FAM_TYPE_nuclear family', 'EDU_LN_yes', 'SCHL_RCV_yes',\n",
      "       'URB_RUR_urban', 'INT_CONN_poor', 'SPOR_PSN_yes', 'COC_PART_yes',\n",
      "       'COC_PART_ROLE_volunteer', 'Cam_plc_yes',\n",
      "       'End term exam SGPA - 1st semester ',\n",
      "       'End term exam SGPA - 2nd semester',\n",
      "       'End term exam SGPA - 3rd semester',\n",
      "       'End term exam SGPA - 4th semester',\n",
      "       'End term exam SGPA - 5th semester',\n",
      "       'End term exam SGPA - 6th semester',\n",
      "       'End term exam SGPA - 7th semester',\n",
      "       'End term exam SGPA - 8th semester', 'CGPA after 8th semester',\n",
      "       'Class X grade', 'Class XII grade', 'Overall Attendance percentage',\n",
      "       'Number of internships during undergraduate.',\n",
      "       'How many hrs you study after school?',\n",
      "       'How many value added program you have entered? (coursera/ AWS/IBM etc)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(processed_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6f578f-6b55-471d-8043-0c9edccda5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Define target variables\n",
    "X_cgpa = processed_data.drop(['CGPA after 8th semester'], axis=1)\n",
    "y_cgpa = processed_data['CGPA after 8th semester']\n",
    "\n",
    "X_placement = processed_data.drop(['Cam_plc_yes'], axis=1)\n",
    "y_placement = processed_data['Cam_plc_yes']\n",
    "# .apply(lambda x: 1 if x == 'yes' else 0)\n",
    "# Split the data\n",
    "X_train_cgpa, X_test_cgpa, y_train_cgpa, y_test_cgpa = train_test_split(X_cgpa, y_cgpa, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data for placement prediction\n",
    "X_train_placement, X_test_placement, y_train_placement, y_test_placement = train_test_split(X_placement, y_placement, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape data for LSTM\n",
    "X_train_cgpa_reshaped = np.reshape(X_train_cgpa.values, (X_train_cgpa.shape[0], X_train_cgpa.shape[1], 1))\n",
    "X_test_cgpa_reshaped = np.reshape(X_test_cgpa.values, (X_test_cgpa.shape[0], X_test_cgpa.shape[1], 1))\n",
    "\n",
    "X_train_placement_reshaped = np.reshape(X_train_placement.values, (X_train_placement.shape[0], X_train_placement.shape[1], 1))\n",
    "X_test_placement_reshaped = np.reshape(X_test_placement.values, (X_test_placement.shape[0], X_test_placement.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b254a152-f5a1-4c0c-8c8a-a2035cccbe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 23:18:51.153790: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-30 23:18:51.179987: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-30 23:18:51.613619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# LSTM model for CGPA prediction\n",
    "def create_cgpa_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    # model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(1, activation='linear'))    \n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "# LSTM model for placement prediction\n",
    "def create_placement_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(1, activation='sigmoid'))  \n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.009)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69d28ac4-1bc4-4fbf-aabb-7bfa6d1d15a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 23:18:52.586190: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/home/bhikrant07/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 1.1554 - mse: 1.1554\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6543 - mse: 0.6543\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3587 - mse: 0.3587\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3443 - mse: 0.3443\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3889 - mse: 0.3889\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3328 - mse: 0.3328\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3189 - mse: 0.3189\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2240 - mse: 0.2240\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2952 - mse: 0.2952\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2771 - mse: 0.2771\n",
      "MSE for CGPA: 0.09814594686031342\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhikrant07/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5667 - loss: 0.6980\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5451 - loss: 0.6937\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4977 - loss: 0.6945\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5371 - loss: 0.6927\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5115 - loss: 0.6922\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5130 - loss: 0.6947\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4925 - loss: 0.6942\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4903 - loss: 0.6927\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5004 - loss: 0.6928\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5010 - loss: 0.6927\n",
      "Accuracy for Placement: 0.6486486196517944\n"
     ]
    }
   ],
   "source": [
    "# Train & evaluate \n",
    "model_cgpa = create_cgpa_lstm_model((X_train_cgpa_reshaped.shape[1], X_train_cgpa_reshaped.shape[2]))\n",
    "                                           #no of timesteps               no of features per timestep\n",
    "model_cgpa.fit(X_train_cgpa_reshaped, y_train_cgpa, epochs=10, batch_size=32, verbose=1)\n",
    "loss_cgpa, mse_cgpa = model_cgpa.evaluate(X_test_cgpa_reshaped, y_test_cgpa, verbose=0)\n",
    "print('MSE for CGPA:', mse_cgpa)\n",
    "\n",
    "\n",
    "model_placement = create_placement_lstm_model((X_train_placement_reshaped.shape[1], X_train_placement_reshaped.shape[2]))\n",
    "model_placement.fit(X_train_placement_reshaped, y_train_placement, epochs=10, batch_size=32, verbose=1)\n",
    "loss_placement, acc_placement = model_placement.evaluate(X_test_placement_reshaped, y_test_placement, verbose=0)\n",
    "print('Accuracy for Placement:', acc_placement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d34fef8-bcc2-4416-8fce-3fbea42b4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In the context of using LSTM (Long Short-Term Memory) models for sequence prediction or classification tasks, reshaping the input data is crucial to match the expected format by the LSTM layer. Let's break down the specifics:\n",
    "\n",
    "# ### Why Reshape for LSTM Models?\n",
    "\n",
    "# 1. **Input Shape Requirement**:\n",
    "#    - LSTM layers in Keras/TensorFlow expect input data in a specific format: `(batch_size, timesteps, input_dim)`.\n",
    "#    - `batch_size`: Number of samples in each batch of data.\n",
    "#    - `timesteps`: Number of time steps or sequence length in each sample.\n",
    "#    - `input_dim`: Number of features (or dimensions) in each time step.\n",
    "\n",
    "# 2. **Reshaping Purpose**:\n",
    "#    - The original shape of your input data might be `(number_of_samples, number_of_features)`. For LSTM models, especially when dealing with sequential data (like time series or text sequences), you reshape it to `(number_of_samples, number_of_timesteps, input_dim)`.\n",
    "\n",
    "# 3. **Specifics of Reshaping**:\n",
    "#    - `X_train_placement.values`: This likely refers to your training data values, typically a DataFrame or array.\n",
    "#    - `X_train_placement.shape[0]`: Refers to the number of samples (rows) in your data.\n",
    "#    - `X_train_placement.shape[1]`: Refers to the number of features (columns) in your data.\n",
    "\n",
    "# 4. **Example Reshaping**:\n",
    "#    - If your original data (`X_train_placement`) has dimensions `(1000, 10)`, it means you have 1000 samples and each sample has 10 features.\n",
    "#    - Reshaping it for LSTM might look like: `X_train_placement_reshaped = np.reshape(X_train_placement.values, (1000, 10, 1))`.\n",
    "#      - Here, `10` becomes `timesteps`, and `1` becomes `input_dim`, assuming you are adding a new dimension for LSTM.\n",
    "\n",
    "# ### Example:\n",
    "\n",
    "# ```python\n",
    "# import numpy as np\n",
    "\n",
    "# # Example data shape\n",
    "# # X_train_placement.shape = (1000, 10)  # 1000 samples, 10 features\n",
    "\n",
    "# # Reshape for LSTM\n",
    "# X_train_placement_reshaped = np.reshape(X_train_placement.values, (1000, 10, 1))\n",
    "# # X_train_placement_reshaped.shape = (1000, 10, 1)  # 1000 samples, 10 timesteps, 1 feature per timestep\n",
    "# ```\n",
    "\n",
    "# ### Summary:\n",
    "\n",
    "# - **Reshaping** for LSTM models ensures your data is formatted correctly `(batch_size, timesteps, input_dim)`.\n",
    "# - `shape[0]` refers to the number of samples (rows), and `shape[1]` refers to the number of features (columns) in your original data.\n",
    "# - The reshaping process adapts your data to fit the requirements of the LSTM layer, enabling it to effectively learn from sequential patterns in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8acd40-9e12-4ee3-b519-e7d48375b6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cgpa_reshaped.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6204047e-d109-4833-8482-7a20b3bfb6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example for prediction\n",
    "\n",
    "# # Predict CGPA for a new student\n",
    "# student_cgpa_data = [/* student data for CGPA prediction */]\n",
    "# student_cgpa_input = np.array(student_cgpa_data).reshape((1, len(student_cgpa_data), 1))\n",
    "# predicted_cgpa = model_cgpa.predict(student_cgpa_input)\n",
    "# print('Predicted CGPA:', predicted_cgpa)\n",
    "\n",
    "# # Predict Placement for a new student\n",
    "# student_placement_data = [/* student data for Placement prediction */]\n",
    "# student_placement_input = np.array(student_placement_data).reshape((1, len(student_placement_data), 1))\n",
    "# predicted_placement = model_placement.predict(student_placement_input)\n",
    "# print('Predicted Placement:', 'Placed' if predicted_placement > 0.5 else 'Not Placed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56786538-7ad4-451f-8737-4e0a28af6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_student_cgpa(student_index):\n",
    "# Select a student for prediction\n",
    "#student_index = 0  # Change this index to select different students\n",
    "    \n",
    "    #individual std data\n",
    "    student_data_a = X_cgpa.iloc[student_index]\n",
    "\n",
    "    # reshape the data for lstm\n",
    "    cgpa_input = np.array(student_data_a).reshape((1, len(student_data_a), 1))\n",
    "    \n",
    "    # Predict CGPA\n",
    "    predicted_cgpa = model_cgpa.predict(cgpa_input)\n",
    "    print('Predicted CGPA (original scale):', predicted_cgpa[0][0])\n",
    "\n",
    "\n",
    "    #trial code to inverse transform\n",
    "    #inverse transform\n",
    "    \n",
    "    y_cgpa = data['CGPA after 8th semester']\n",
    "    y_train_cgpa = np.array(y_cgpa.values)\n",
    "    scaler = StandardScaler()\n",
    "    y_train_cgpa_scaled = scaler.fit_transform(y_train_cgpa.reshape(-1, 1)) #fit the data\n",
    "    predicted_cgpa_original = scaler.inverse_transform(predicted_cgpa) #now do inverse transform\n",
    "    print('Predicted CGPA (original scale):', predicted_cgpa_original[0][0])\n",
    "\n",
    "\n",
    "def predict_student_placement(student_index):\n",
    "    \n",
    "    student_data_b = X_placement.iloc[student_index]\n",
    "    \n",
    "    #same for placemernt\n",
    "    placement_input = np.array(student_data_b).reshape((1, len(student_data_b), 1))\n",
    "    \n",
    "    # Predict Placement\n",
    "    predicted_placement = model_placement.predict(placement_input)\n",
    "    print('Predicted Placement:', 'Placed' if predicted_placement[0][0] > 0.5 else 'Not Placed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2efd6e02-994f-4d05-9970-12dfab25b46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "Predicted CGPA (original scale): -0.43841696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
      "Predicted Placement: Placed\n"
     ]
    }
   ],
   "source": [
    "predict_student_cgpa(0)\n",
    "predict_student_placement(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9ce4bd7-935f-41ae-9f64-37833ad75d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7591614943875791"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.iloc[0]['CGPA after 8th semester']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe9b469-3a08-4e9a-b274-69fffa0cea42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]['Cam_plc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58588850-bb53-49fc-ace2-6559863017b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
