{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c561848d-3e7f-4033-90ba-0bb824864640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 16:19:06.690328: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-08 16:19:06.714301: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-08 16:19:06.714341: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-08 16:19:06.726462: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-08 16:19:07.514904: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/tmp/ipykernel_73936/2528587920.py:7: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10452c81-642f-4a43-a04c-c81b4b999845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Branch               Cepo  Program  End term exam SGPA - 1st semester   \\\n",
      "0    CSE  Currently enrolled  B.Tech                                 6.5   \n",
      "\n",
      "   End term exam SGPA - 2nd semester  End term exam SGPA - 3rd semester  \\\n",
      "0                                7.2                                6.1   \n",
      "\n",
      "   End term exam SGPA - 4th semester  End term exam SGPA - 5th semester  \\\n",
      "0                                8.2                                6.8   \n",
      "\n",
      "   End term exam SGPA - 6th semester  End term exam SGPA - 7th semester  ...  \\\n",
      "0                                6.6                                6.3  ...   \n",
      "\n",
      "   EDU_LN  SCHL_RCV  URB_RUR INT_CONN How many hrs you study after school?  \\\n",
      "0     Yes        No    Urban     Good                                    1   \n",
      "\n",
      "   How many value added program you have entered? (coursera/ AWS/IBM etc)  \\\n",
      "0                                                  2                        \n",
      "\n",
      "   SPOR_PSN  COC_PART COC_PART_ROLE Cam_plc  \n",
      "0       Yes       yes   Team leader     Yes  \n",
      "\n",
      "[1 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/bhikrant07/Desktop/AI/KU_STUDENT_DATA_ON_CAMPUS_PLACEMENT.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f173486-f823-4283-be2a-f7e327896199",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x) \n",
    "\n",
    "# Splitting the data for CGPA prediction\n",
    "X_cgpa = data.drop(['CGPA after 8th semester', 'Cam_plc'], axis=1)\n",
    "y_cgpa = data['CGPA after 8th semester']\n",
    "\n",
    "X_train_cgpa, X_test_cgpa, y_train_cgpa, y_test_cgpa = train_test_split(X_cgpa, y_cgpa, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting the data for placement prediction (including CGPA as a feature)\n",
    "X_placement = data.drop(['Cam_plc'], axis=1)\n",
    "y_placement = data['Cam_plc']\n",
    "\n",
    "X_train_placement, X_test_placement, y_train_placement, y_test_placement = train_test_split(X_placement, y_placement, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a27785-8a94-417b-bf71-787742dae686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the encoders and scalers on the training data only\n",
    "categorical_features = X_cgpa.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features_cgpa = X_cgpa.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numerical_features_placement = X_placement.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "scaler_cgpa = StandardScaler()\n",
    "scaler_placement = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28022e10-088d-4940-97f0-dd77d7dcb0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the target variable 'y' for both train and test sets\n",
    "y_train_placement = label_encoder.fit_transform(y_train_placement)\n",
    "y_test_placement = label_encoder.transform(y_test_placement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9ad943f-9398-41e1-9337-9f9ac33a7fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CGPA data\n",
    "X_train_categorical_cgpa = encoder.fit_transform(X_train_cgpa[categorical_features])\n",
    "X_test_categorical_cgpa = encoder.transform(X_test_cgpa[categorical_features])\n",
    "\n",
    "X_train_numerical_cgpa = scaler_cgpa.fit_transform(X_train_cgpa[numerical_features_cgpa])\n",
    "X_test_numerical_cgpa = scaler_cgpa.transform(X_test_cgpa[numerical_features_cgpa])\n",
    "\n",
    "X_train_processed_cgpa = pd.concat([pd.DataFrame(X_train_categorical_cgpa, columns=encoder.get_feature_names_out(categorical_features)),\n",
    "                                    pd.DataFrame(X_train_numerical_cgpa, columns=numerical_features_cgpa)], axis=1)\n",
    "X_test_processed_cgpa = pd.concat([pd.DataFrame(X_test_categorical_cgpa, columns=encoder.get_feature_names_out(categorical_features)),\n",
    "                                   pd.DataFrame(X_test_numerical_cgpa, columns=numerical_features_cgpa)], axis=1)\n",
    "\n",
    "# Process Placement data\n",
    "X_train_categorical_placement = encoder.transform(X_train_placement[categorical_features])\n",
    "X_test_categorical_placement = encoder.transform(X_test_placement[categorical_features])\n",
    "\n",
    "X_train_numerical_placement = scaler_placement.fit_transform(X_train_placement[numerical_features_placement])\n",
    "X_test_numerical_placement = scaler_placement.transform(X_test_placement[numerical_features_placement])\n",
    "\n",
    "X_train_processed_placement = pd.concat([pd.DataFrame(X_train_categorical_placement, columns=encoder.get_feature_names_out(categorical_features)),\n",
    "                                         pd.DataFrame(X_train_numerical_placement, columns=numerical_features_placement)], axis=1)\n",
    "X_test_processed_placement = pd.concat([pd.DataFrame(X_test_categorical_placement, columns=encoder.get_feature_names_out(categorical_features)),\n",
    "                                        pd.DataFrame(X_test_numerical_placement, columns=numerical_features_placement)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b97c2a-6570-4d56-8768-bc27dd5d165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Branch_cse  Branch_ece  Branch_ee  Branch_me  Branch_mscit  \\\n",
      "0         0.0         0.0        0.0        1.0           0.0   \n",
      "\n",
      "   Cepo _passed out  Program_mscit  C_X_B_state board  C_XII_B_state board  \\\n",
      "0               0.0            0.0                0.0                  1.0   \n",
      "\n",
      "   M_F_male  ...  End term exam SGPA - 6th semester  \\\n",
      "0       0.0  ...                           0.523461   \n",
      "\n",
      "   End term exam SGPA - 7th semester  End term exam SGPA - 8th semester  \\\n",
      "0                          -0.660108                          -0.694831   \n",
      "\n",
      "   CGPA after 8th semester  Class X grade  Class XII grade  \\\n",
      "0                 -0.77013      -0.054577         0.080749   \n",
      "\n",
      "   Overall Attendance percentage  Number of internships during undergraduate.  \\\n",
      "0                       0.166957                                     0.168771   \n",
      "\n",
      "   How many hrs you study after school?  \\\n",
      "0                              -0.71617   \n",
      "\n",
      "   How many value added program you have entered? (coursera/ AWS/IBM etc)  \n",
      "0                                          -0.758733                       \n",
      "\n",
      "[1 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_processed_placement.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b57098c4-aaed-4338-83d1-0a40e0ac311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for LSTM input\n",
    "X_train_cgpa_reshaped = np.reshape(X_train_processed_cgpa.values, (X_train_processed_cgpa.shape[0], X_train_processed_cgpa.shape[1], 1))\n",
    "X_test_cgpa_reshaped = np.reshape(X_test_processed_cgpa.values, (X_test_processed_cgpa.shape[0], X_test_processed_cgpa.shape[1], 1))\n",
    "\n",
    "X_train_placement_reshaped = np.reshape(X_train_processed_placement.values, (X_train_processed_placement.shape[0], X_train_processed_placement.shape[1], 1))\n",
    "X_test_placement_reshaped = np.reshape(X_test_processed_placement.values, (X_test_processed_placement.shape[0], X_test_processed_placement.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5e7e77-2b51-406d-accb-3f383d0c17c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model building function for CGPA prediction\n",
    "def build_model_cgpa(hp):\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(LSTM(units=hp.Int('units_' + str(i), min_value=32, max_value=128, step=32),\n",
    "                       return_sequences=True if i < hp.Int('num_layers', 1, 3) - 1 else False,\n",
    "                       input_shape=(X_train_cgpa_reshaped.shape[1], 1)))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_' + str(i), min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Define the model building function for placement prediction\n",
    "def build_model_placement(hp):\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(LSTM(units=hp.Int('units_' + str(i), min_value=32, max_value=128, step=32),\n",
    "                       return_sequences=True if i < hp.Int('num_layers', 1, 3) - 1 else False,\n",
    "                       input_shape=(X_train_placement_reshaped.shape[1], 1)))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_' + str(i), min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "603d1bac-3b4a-4b0d-bab6-c9ac94bdd430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/cgpa_tuning/tuner0.json\n",
      "Best CGPA Hyperparameters: {'num_layers': 2, 'units_0': 32, 'dropout_0': 0.2, 'units_1': 64, 'dropout_1': 0.4, 'units_2': 96, 'dropout_2': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning with Keras Tuner for CGPA prediction\n",
    "tuner_cgpa = RandomSearch(build_model_cgpa,\n",
    "                          objective='val_loss',\n",
    "                          max_trials=5,\n",
    "                          executions_per_trial=3,\n",
    "                          directory='my_dir',\n",
    "                          project_name='cgpa_tuning')\n",
    "\n",
    "tuner_cgpa.search(X_train_cgpa_reshaped, y_train_cgpa, epochs=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps_cgpa = tuner_cgpa.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f'Best CGPA Hyperparameters: {best_hps_cgpa.values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6a199a5-f4e9-4fe6-b079-89f983a58f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 16:19:09.807467: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/placement_tuning/tuner0.json\n",
      "Best Placement Hyperparameters: {'num_layers': 1, 'units_0': 128, 'dropout_0': 0.4, 'units_1': 96, 'dropout_1': 0.30000000000000004, 'units_2': 32, 'dropout_2': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning with Keras Tuner for placement prediction\n",
    "tuner_placement = RandomSearch(\n",
    "    build_model_placement,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='placement_tuning')\n",
    "\n",
    "tuner_placement.search(X_train_placement_reshaped, y_train_placement, epochs=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "# Get the optimal hyperparameters for placement prediction\n",
    "best_hps_placement = tuner_placement.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f'Best Placement Hyperparameters: {best_hps_placement.values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20ad2ae0-d52b-4ac0-91fd-51768058ef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhikrant07/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 49.5578 - val_loss: 43.0747\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 37.0247 - val_loss: 13.5128\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.7793 - val_loss: 1.7883\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6268 - val_loss: 1.0123\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0561 - val_loss: 1.0498\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6059 - val_loss: 0.8828\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5756 - val_loss: 1.0795\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6645 - val_loss: 1.0563\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7119 - val_loss: 0.8856\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2997 - val_loss: 0.8426\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5404 - val_loss: 0.8326\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5567 - val_loss: 0.8417\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6563 - val_loss: 0.8308\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2213 - val_loss: 0.8479\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6392 - val_loss: 0.7926\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2058 - val_loss: 0.7624\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.1922 - val_loss: 0.7499\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4526 - val_loss: 0.7464\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2066 - val_loss: 0.6801\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2318 - val_loss: 0.6439\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3500 - val_loss: 0.6852\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4252 - val_loss: 0.5963\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3114 - val_loss: 0.5715\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2278 - val_loss: 0.5578\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1764 - val_loss: 0.5694\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1352 - val_loss: 0.5306\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3042 - val_loss: 0.5187\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2116 - val_loss: 0.5611\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2482 - val_loss: 0.4919\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0917 - val_loss: 0.4778\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2076 - val_loss: 0.4965\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9741 - val_loss: 0.4945\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2315 - val_loss: 0.5299\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0629 - val_loss: 0.4939\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9949 - val_loss: 0.4906\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9366 - val_loss: 0.4764\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0318 - val_loss: 0.4654\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.9374 - val_loss: 0.4774\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1119 - val_loss: 0.4536\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1748 - val_loss: 0.4679\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9668 - val_loss: 0.4412\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1044 - val_loss: 0.4297\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0104 - val_loss: 0.4454\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0459 - val_loss: 0.4160\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1879 - val_loss: 0.4592\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9427 - val_loss: 0.4115\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0843 - val_loss: 0.4016\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.8237 - val_loss: 0.3803\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.9366 - val_loss: 0.3610\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9522 - val_loss: 0.3411\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhikrant07/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.5114 - loss: 0.6949 - val_accuracy: 0.5085 - val_loss: 0.6926\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5297 - loss: 0.6931 - val_accuracy: 0.4915 - val_loss: 0.6930\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5824 - loss: 0.6894 - val_accuracy: 0.4915 - val_loss: 0.6925\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5215 - loss: 0.6975 - val_accuracy: 0.5424 - val_loss: 0.6912\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5381 - loss: 0.6886 - val_accuracy: 0.4576 - val_loss: 0.6912\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4283 - loss: 0.6935 - val_accuracy: 0.5085 - val_loss: 0.6911\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5036 - loss: 0.6908 - val_accuracy: 0.5254 - val_loss: 0.6912\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5065 - loss: 0.6902 - val_accuracy: 0.5424 - val_loss: 0.6908\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5019 - loss: 0.6928 - val_accuracy: 0.6271 - val_loss: 0.6890\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5283 - loss: 0.6922 - val_accuracy: 0.6271 - val_loss: 0.6884\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5547 - loss: 0.6906 - val_accuracy: 0.5932 - val_loss: 0.6873\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5357 - loss: 0.6878 - val_accuracy: 0.6102 - val_loss: 0.6860\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4990 - loss: 0.6895 - val_accuracy: 0.5593 - val_loss: 0.6863\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5318 - loss: 0.6891 - val_accuracy: 0.5085 - val_loss: 0.6884\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5633 - loss: 0.6860 - val_accuracy: 0.5932 - val_loss: 0.6846\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5293 - loss: 0.6879 - val_accuracy: 0.6102 - val_loss: 0.6836\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5690 - loss: 0.6841 - val_accuracy: 0.6271 - val_loss: 0.6819\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5681 - loss: 0.6835 - val_accuracy: 0.5593 - val_loss: 0.6825\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6029 - loss: 0.6771 - val_accuracy: 0.6610 - val_loss: 0.6810\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5558 - loss: 0.6823 - val_accuracy: 0.6610 - val_loss: 0.6797\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5086 - loss: 0.6844 - val_accuracy: 0.5254 - val_loss: 0.6842\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5323 - loss: 0.6904 - val_accuracy: 0.5085 - val_loss: 0.6867\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5234 - loss: 0.6854 - val_accuracy: 0.4915 - val_loss: 0.6840\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5452 - loss: 0.6878 - val_accuracy: 0.6271 - val_loss: 0.6815\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6113 - loss: 0.6813 - val_accuracy: 0.6271 - val_loss: 0.6794\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5445 - loss: 0.6856 - val_accuracy: 0.6102 - val_loss: 0.6772\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5626 - loss: 0.6834 - val_accuracy: 0.6102 - val_loss: 0.6761\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5732 - loss: 0.6859 - val_accuracy: 0.6271 - val_loss: 0.6736\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5706 - loss: 0.6768 - val_accuracy: 0.6610 - val_loss: 0.6665\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5415 - loss: 0.6778 - val_accuracy: 0.5932 - val_loss: 0.6678\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5801 - loss: 0.6795 - val_accuracy: 0.5424 - val_loss: 0.6854\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4928 - loss: 0.6869 - val_accuracy: 0.5932 - val_loss: 0.6827\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5059 - loss: 0.6914 - val_accuracy: 0.5085 - val_loss: 0.6745\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5625 - loss: 0.6725 - val_accuracy: 0.5593 - val_loss: 0.6786\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5362 - loss: 0.6826 - val_accuracy: 0.6441 - val_loss: 0.6666\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5991 - loss: 0.6580 - val_accuracy: 0.6271 - val_loss: 0.6616\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5717 - loss: 0.6774 - val_accuracy: 0.6102 - val_loss: 0.6632\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5589 - loss: 0.6676 - val_accuracy: 0.5424 - val_loss: 0.6543\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5999 - loss: 0.6587 - val_accuracy: 0.5593 - val_loss: 0.6481\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6035 - loss: 0.6465 - val_accuracy: 0.5424 - val_loss: 0.6560\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5865 - loss: 0.6534 - val_accuracy: 0.5932 - val_loss: 0.6521\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6075 - loss: 0.6440 - val_accuracy: 0.5593 - val_loss: 0.6691\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5742 - loss: 0.6622 - val_accuracy: 0.5763 - val_loss: 0.6518\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6298 - loss: 0.6513 - val_accuracy: 0.6271 - val_loss: 0.6418\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6003 - loss: 0.6484 - val_accuracy: 0.5254 - val_loss: 0.6443\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6271 - loss: 0.6301 - val_accuracy: 0.6102 - val_loss: 0.6424\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6234 - loss: 0.6465 - val_accuracy: 0.6441 - val_loss: 0.6418\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6256 - loss: 0.6304 - val_accuracy: 0.6271 - val_loss: 0.6460\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6164 - loss: 0.6392 - val_accuracy: 0.6610 - val_loss: 0.6309\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6678 - loss: 0.6103 - val_accuracy: 0.5763 - val_loss: 0.6465\n"
     ]
    }
   ],
   "source": [
    "# Build and train the final CGPA model\n",
    "model_cgpa = tuner_cgpa.hypermodel.build(best_hps_cgpa)\n",
    "epochs_cgpa = best_hps_cgpa['epochs'] if 'epochs' in best_hps_cgpa else 50  # Default to 50 if 'epochs' is not found\n",
    "history_cgpa = model_cgpa.fit(X_train_cgpa_reshaped, y_train_cgpa, epochs=epochs_cgpa, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=10)])\n",
    "\n",
    "# Build and train the final placement model\n",
    "model_placement = tuner_placement.hypermodel.build(best_hps_placement)\n",
    "epochs_placement = best_hps_placement['epochs'] if 'epochs' in best_hps_placement else 50  # Default to 50 if 'epochs' is not found\n",
    "history_placement = model_placement.fit(X_train_placement_reshaped, y_train_placement, epochs=epochs_placement, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc2c10da-543c-427e-a5f2-969c72dfde50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Optimal Threshold: 0.5985777378082275\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Assuming you have your model and test data ready\n",
    "# X_test: test features\n",
    "# y_test: true labels\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_prob = model_placement.predict(X_test_placement_reshaped).flatten()  # Assuming binary classification\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_placement, y_pred_prob)\n",
    "\n",
    "# Compute the optimal threshold\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "print(f'Optimal Threshold: {optimal_threshold}')\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', color='black', label='Optimal threshold')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e73fd128-280c-4142-9896-92af1c9682ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhikrant07/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 47.9329 - val_loss: 12.2728\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.8723 - val_loss: 1.2183\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.7253 - val_loss: 1.1082\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.2424 - val_loss: 1.0117\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.3811 - val_loss: 0.9320\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.3319 - val_loss: 0.9180\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.1764 - val_loss: 0.8862\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.5217 - val_loss: 0.8654\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.3113 - val_loss: 0.8248\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.3532 - val_loss: 0.8607\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.1766 - val_loss: 0.8369\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.3285 - val_loss: 0.6057\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.9906 - val_loss: 0.5531\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.9077 - val_loss: 0.4399\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.9782 - val_loss: 0.4964\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.9209 - val_loss: 0.3645\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.9694 - val_loss: 0.2972\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.7086 - val_loss: 0.2045\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.6275 - val_loss: 0.1707\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.9461 - val_loss: 0.1655\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6170 - val_loss: 0.1681\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.6693 - val_loss: 0.1660\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6544 - val_loss: 0.1197\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.7865 - val_loss: 0.1842\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.6781 - val_loss: 0.1880\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.6930 - val_loss: 0.1770\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5981 - val_loss: 0.1843\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6738 - val_loss: 0.1585\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6203 - val_loss: 0.2044\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6232 - val_loss: 0.1543\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7068 - val_loss: 0.1466\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7274 - val_loss: 0.1629\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6436 - val_loss: 0.1716\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.7669 - val_loss: 0.1363\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6754 - val_loss: 0.1426\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7700 - val_loss: 0.1526\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.8733 - val_loss: 0.1750\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5951 - val_loss: 0.2375\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7020 - val_loss: 0.1671\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7042 - val_loss: 0.3814\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.8609 - val_loss: 0.2110\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.7302 - val_loss: 0.2653\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6308 - val_loss: 0.1886\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6814 - val_loss: 0.1440\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6357 - val_loss: 0.1947\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6068 - val_loss: 0.1400\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.7346 - val_loss: 0.1267\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5371 - val_loss: 0.1348\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5677 - val_loss: 0.1515\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6356 - val_loss: 0.1605\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6269 - val_loss: 0.1157\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.6220 - val_loss: 0.1634\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5773 - val_loss: 0.1746\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6016 - val_loss: 0.1777\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.7238 - val_loss: 0.1478\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5845 - val_loss: 0.2050\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5344 - val_loss: 0.2229\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.7036 - val_loss: 0.1511\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5571 - val_loss: 0.1347\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.6006 - val_loss: 0.1376\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5966 - val_loss: 0.1693\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5578 - val_loss: 0.1360\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.6348 - val_loss: 0.1496\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5978 - val_loss: 0.1267\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5713 - val_loss: 0.1292\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5472 - val_loss: 0.1202\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7699 - val_loss: 0.1493\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6066 - val_loss: 0.1363\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5734 - val_loss: 0.1364\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.6113 - val_loss: 0.1566\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5890 - val_loss: 0.1323\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5626 - val_loss: 0.1804\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6817 - val_loss: 0.1379\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5973 - val_loss: 0.1494\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5810 - val_loss: 0.1341\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5539 - val_loss: 0.1265\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.7156 - val_loss: 0.1790\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5447 - val_loss: 0.1829\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5495 - val_loss: 0.1143\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6695 - val_loss: 0.1432\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6881 - val_loss: 0.1441\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6345 - val_loss: 0.1412\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.6528 - val_loss: 0.1659\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6552 - val_loss: 0.2088\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5606 - val_loss: 0.1146\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5392 - val_loss: 0.0941\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5724 - val_loss: 0.1638\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6264 - val_loss: 0.1258\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6114 - val_loss: 0.1448\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4533 - val_loss: 0.1398\n",
      "X_test_cgpa_reshaped shape: (74, 34, 1)\n",
      "y_test_cgpa shape: (74,)\n",
      "Evaluation result: 0.13977009057998657\n",
      "MSE for CGPA: 0.13977009057998657\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhikrant07/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4844 - loss: 0.6948 - val_accuracy: 0.5541 - val_loss: 0.6917\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5503 - loss: 0.6918 - val_accuracy: 0.4324 - val_loss: 0.6938\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5446 - loss: 0.6922 - val_accuracy: 0.4324 - val_loss: 0.6978\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5190 - loss: 0.6909 - val_accuracy: 0.4459 - val_loss: 0.6932\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5468 - loss: 0.6906 - val_accuracy: 0.4730 - val_loss: 0.6910\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5541 - loss: 0.6895 - val_accuracy: 0.4595 - val_loss: 0.6903\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5452 - loss: 0.6900 - val_accuracy: 0.4730 - val_loss: 0.6925\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5629 - loss: 0.6886 - val_accuracy: 0.4865 - val_loss: 0.6889\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5018 - loss: 0.6908 - val_accuracy: 0.5270 - val_loss: 0.6943\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5619 - loss: 0.6856 - val_accuracy: 0.5270 - val_loss: 0.6981\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5538 - loss: 0.6870 - val_accuracy: 0.6081 - val_loss: 0.6855\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5445 - loss: 0.6903 - val_accuracy: 0.6081 - val_loss: 0.6854\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5705 - loss: 0.6845 - val_accuracy: 0.6351 - val_loss: 0.6758\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5689 - loss: 0.6842 - val_accuracy: 0.5000 - val_loss: 0.6879\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5576 - loss: 0.6827 - val_accuracy: 0.5135 - val_loss: 0.6933\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5642 - loss: 0.6838 - val_accuracy: 0.5541 - val_loss: 0.6921\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5619 - loss: 0.6821 - val_accuracy: 0.5811 - val_loss: 0.6835\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6140 - loss: 0.6803 - val_accuracy: 0.5676 - val_loss: 0.6743\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5503 - loss: 0.6825 - val_accuracy: 0.5000 - val_loss: 0.6790\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5580 - loss: 0.6847 - val_accuracy: 0.5405 - val_loss: 0.6737\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5766 - loss: 0.6774 - val_accuracy: 0.5541 - val_loss: 0.6620\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5641 - loss: 0.6773 - val_accuracy: 0.4595 - val_loss: 0.6893\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5411 - loss: 0.6772 - val_accuracy: 0.5405 - val_loss: 0.6630\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5720 - loss: 0.6813 - val_accuracy: 0.6081 - val_loss: 0.6515\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5394 - loss: 0.6676 - val_accuracy: 0.4865 - val_loss: 0.6875\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5921 - loss: 0.6633 - val_accuracy: 0.5405 - val_loss: 0.6520\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5844 - loss: 0.6582 - val_accuracy: 0.5000 - val_loss: 0.6568\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5850 - loss: 0.6526 - val_accuracy: 0.5000 - val_loss: 0.6576\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5913 - loss: 0.6443 - val_accuracy: 0.4324 - val_loss: 0.7067\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5788 - loss: 0.6703 - val_accuracy: 0.5946 - val_loss: 0.6318\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5420 - loss: 0.6813 - val_accuracy: 0.7027 - val_loss: 0.6311\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6313 - loss: 0.6421 - val_accuracy: 0.7027 - val_loss: 0.6340\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6171 - loss: 0.6494 - val_accuracy: 0.6081 - val_loss: 0.6435\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6510 - loss: 0.6360 - val_accuracy: 0.6216 - val_loss: 0.6479\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6302 - loss: 0.6410 - val_accuracy: 0.6081 - val_loss: 0.6430\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6149 - loss: 0.6392 - val_accuracy: 0.5135 - val_loss: 0.6686\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6567 - loss: 0.6318 - val_accuracy: 0.5135 - val_loss: 0.6500\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6248 - loss: 0.6309 - val_accuracy: 0.5000 - val_loss: 0.6724\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6527 - loss: 0.6379 - val_accuracy: 0.5270 - val_loss: 0.6625\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6762 - loss: 0.6149 - val_accuracy: 0.5811 - val_loss: 0.6371\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7125 - loss: 0.6082 - val_accuracy: 0.5541 - val_loss: 0.6563\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6477 - loss: 0.6331 - val_accuracy: 0.5541 - val_loss: 0.6487\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6351 - loss: 0.6189 - val_accuracy: 0.5270 - val_loss: 0.6487\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6384 - loss: 0.6118 - val_accuracy: 0.5270 - val_loss: 0.6774\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6631 - loss: 0.6018 - val_accuracy: 0.5405 - val_loss: 0.6626\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6714 - loss: 0.5960 - val_accuracy: 0.5405 - val_loss: 0.6561\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7028 - loss: 0.5911 - val_accuracy: 0.5811 - val_loss: 0.6582\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6823 - loss: 0.5877 - val_accuracy: 0.5541 - val_loss: 0.6783\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6681 - loss: 0.5682 - val_accuracy: 0.5270 - val_loss: 0.6536\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6174 - loss: 0.6150 - val_accuracy: 0.5676 - val_loss: 0.6671\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6488 - loss: 0.6045 - val_accuracy: 0.5541 - val_loss: 0.6715\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6677 - loss: 0.6039 - val_accuracy: 0.5541 - val_loss: 0.6657\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7126 - loss: 0.5666 - val_accuracy: 0.5676 - val_loss: 0.6369\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7118 - loss: 0.5819 - val_accuracy: 0.5676 - val_loss: 0.6641\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7189 - loss: 0.5517 - val_accuracy: 0.5405 - val_loss: 0.6690\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6937 - loss: 0.5412 - val_accuracy: 0.5000 - val_loss: 0.6758\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6654 - loss: 0.5686 - val_accuracy: 0.5541 - val_loss: 0.6540\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7173 - loss: 0.5728 - val_accuracy: 0.5000 - val_loss: 0.6626\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6676 - loss: 0.5598 - val_accuracy: 0.5676 - val_loss: 0.6686\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6808 - loss: 0.5555 - val_accuracy: 0.6216 - val_loss: 0.6702\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6644 - loss: 0.5580 - val_accuracy: 0.4865 - val_loss: 0.6986\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7127 - loss: 0.5185 - val_accuracy: 0.5000 - val_loss: 0.6929\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6947 - loss: 0.5447 - val_accuracy: 0.5000 - val_loss: 0.6955\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7053 - loss: 0.5397 - val_accuracy: 0.5541 - val_loss: 0.6882\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6406 - loss: 0.5848 - val_accuracy: 0.5135 - val_loss: 0.6752\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7190 - loss: 0.5403 - val_accuracy: 0.5676 - val_loss: 0.6579\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7301 - loss: 0.5454 - val_accuracy: 0.4730 - val_loss: 0.7396\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7422 - loss: 0.5099 - val_accuracy: 0.5270 - val_loss: 0.6677\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7266 - loss: 0.5179 - val_accuracy: 0.4595 - val_loss: 0.7274\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6927 - loss: 0.5352 - val_accuracy: 0.5000 - val_loss: 0.7099\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7499 - loss: 0.5063 - val_accuracy: 0.5541 - val_loss: 0.6962\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7317 - loss: 0.5245 - val_accuracy: 0.5405 - val_loss: 0.7146\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6763 - loss: 0.5443 - val_accuracy: 0.5676 - val_loss: 0.6583\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7594 - loss: 0.4881 - val_accuracy: 0.4730 - val_loss: 0.7119\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7167 - loss: 0.5191 - val_accuracy: 0.5811 - val_loss: 0.6835\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7638 - loss: 0.5071 - val_accuracy: 0.5135 - val_loss: 0.6780\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7394 - loss: 0.4871 - val_accuracy: 0.5676 - val_loss: 0.7089\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6878 - loss: 0.5693 - val_accuracy: 0.5946 - val_loss: 0.6924\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7481 - loss: 0.4949 - val_accuracy: 0.5541 - val_loss: 0.7247\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6820 - loss: 0.5858 - val_accuracy: 0.5946 - val_loss: 0.6803\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7667 - loss: 0.4684 - val_accuracy: 0.5946 - val_loss: 0.6975\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7912 - loss: 0.4313 - val_accuracy: 0.5946 - val_loss: 0.6623\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7990 - loss: 0.4457 - val_accuracy: 0.5946 - val_loss: 0.6915\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8308 - loss: 0.4341 - val_accuracy: 0.6216 - val_loss: 0.6708\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7437 - loss: 0.4977 - val_accuracy: 0.5811 - val_loss: 0.7244\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7159 - loss: 0.5442 - val_accuracy: 0.5676 - val_loss: 0.8169\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6372 - loss: 0.6723 - val_accuracy: 0.5405 - val_loss: 0.7350\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6807 - loss: 0.5860 - val_accuracy: 0.5405 - val_loss: 0.7191\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6966 - loss: 0.5459 - val_accuracy: 0.5946 - val_loss: 0.6748\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7249 - loss: 0.5278 - val_accuracy: 0.5676 - val_loss: 0.6739\n",
      "Accuracy for Placement: 0.5675675868988037\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Assuming you have imported necessary libraries and defined tuner_cgpa, tuner_placement, X_train_cgpa_reshaped, y_train_cgpa, X_test_cgpa_reshaped, y_test_cgpa, X_train_placement_reshaped, y_train_placement, X_test_placement_reshaped, y_test_placement correctly\n",
    "\n",
    "# Load the best hyperparameters for CGPA prediction\n",
    "with open('best_hps_cgpa.pkl', 'rb') as f:\n",
    "    best_hps_cgpa = pickle.load(f)\n",
    "\n",
    "# Build and train the CGPA prediction model using the best hyperparameters\n",
    "model_cgpa = tuner_cgpa.hypermodel.build(best_hps_cgpa)\n",
    "model_cgpa.fit(X_train_cgpa_reshaped, y_train_cgpa, epochs=100, initial_epoch=10, validation_data=(X_test_cgpa_reshaped, y_test_cgpa))\n",
    "# Assuming model_cgpa is defined and compiled correctly\n",
    "\n",
    "# Print the shapes of X_test_cgpa_reshaped and y_test_cgpa\n",
    "print('X_test_cgpa_reshaped shape:', X_test_cgpa_reshaped.shape)\n",
    "print('y_test_cgpa shape:', y_test_cgpa.shape)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_result = model_cgpa.evaluate(X_test_cgpa_reshaped, y_test_cgpa, verbose=0)\n",
    "print('Evaluation result:', evaluation_result)\n",
    "\n",
    "# Assuming evaluation_result is a float, you can access the MSE directly\n",
    "mse_cgpa = evaluation_result\n",
    "print('MSE for CGPA:', mse_cgpa)\n",
    "\n",
    "# Load the best hyperparameters for placement prediction\n",
    "with open('best_hps_placement.pkl', 'rb') as f:\n",
    "    best_hps_placement = pickle.load(f)\n",
    "\n",
    "# Build and train the placement prediction model using the best hyperparameters\n",
    "model_placement = tuner_placement.hypermodel.build(best_hps_placement)\n",
    "model_placement.fit(X_train_placement_reshaped, y_train_placement, epochs=100, initial_epoch=10, validation_data=(X_test_placement_reshaped, y_test_placement))\n",
    "loss_placement, acc_placement = model_placement.evaluate(X_test_placement_reshaped, y_test_placement, verbose=0)\n",
    "print('Accuracy for Placement:', acc_placement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0da1bf82-1819-46ca-a915-bf4e7fc5b274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_processed_cgpa shape: (74, 34)\n",
      "X_test_processed_placement shape: (74, 35)\n",
      "X_test_processed_placement shape: (74, 35)\n",
      "9.13\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test_processed_placement shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, X_test_processed_placement\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m10\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCGPA after 8th semester\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m predict_student_cgpa(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m10\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCam_plc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m predict_student_placement(\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m, in \u001b[0;36mpredict_student_cgpa\u001b[0;34m(student_index)\u001b[0m\n\u001b[1;32m      9\u001b[0m cgpa_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(numeric_student_data_a, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(numeric_student_data_a)))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Perform CGPA prediction using model_cgpa\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m predicted_cgpa \u001b[38;5;241m=\u001b[39m model_cgpa\u001b[38;5;241m.\u001b[39mpredict(cgpa_input)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Assuming scaler was fit with a single column\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Reshape predicted_cgpa for inverse transform to match scaler input shape\u001b[39;00m\n\u001b[1;32m     16\u001b[0m predicted_cgpa_reshaped \u001b[38;5;241m=\u001b[39m predicted_cgpa\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Assuming a single prediction for one student\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Test the functions\n",
    "print('X_test_processed_placement shape:', X_test_processed_placement.shape)\n",
    "print(data.iloc[10]['CGPA after 8th semester'])\n",
    "predict_student_cgpa(10)\n",
    "print(data.iloc[10]['Cam_plc'])\n",
    "predict_student_placement(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e2c75-e1d0-48f1-84e6-642fb92bfffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8791d4b-7b64-408f-aed6-1f4d43c1e870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
