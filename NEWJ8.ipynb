{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c561848d-3e7f-4033-90ba-0bb824864640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 15:16:46.680802: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-08 15:16:46.701994: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-08 15:16:46.702023: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-08 15:16:46.713822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-08 15:16:47.431256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/tmp/ipykernel_60774/2528587920.py:7: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10452c81-642f-4a43-a04c-c81b4b999845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Branch               Cepo  Program  End term exam SGPA - 1st semester   \\\n",
      "0    CSE  Currently enrolled  B.Tech                                 6.5   \n",
      "\n",
      "   End term exam SGPA - 2nd semester  End term exam SGPA - 3rd semester  \\\n",
      "0                                7.2                                6.1   \n",
      "\n",
      "   End term exam SGPA - 4th semester  End term exam SGPA - 5th semester  \\\n",
      "0                                8.2                                6.8   \n",
      "\n",
      "   End term exam SGPA - 6th semester  End term exam SGPA - 7th semester  ...  \\\n",
      "0                                6.6                                6.3  ...   \n",
      "\n",
      "   EDU_LN  SCHL_RCV  URB_RUR INT_CONN How many hrs you study after school?  \\\n",
      "0     Yes        No    Urban     Good                                    1   \n",
      "\n",
      "   How many value added program you have entered? (coursera/ AWS/IBM etc)  \\\n",
      "0                                                  2                        \n",
      "\n",
      "   SPOR_PSN  COC_PART COC_PART_ROLE Cam_plc  \n",
      "0       Yes       yes   Team leader     Yes  \n",
      "\n",
      "[1 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/bhikrant07/Desktop/AI/KU_STUDENT_DATA_ON_CAMPUS_PLACEMENT.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f173486-f823-4283-be2a-f7e327896199",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x) \n",
    "\n",
    "# Splitting the data for CGPA prediction\n",
    "X_cgpa = data.drop(['CGPA after 8th semester', 'Cam_plc'], axis=1)\n",
    "y_cgpa = data['CGPA after 8th semester']\n",
    "\n",
    "X_train_cgpa, X_test_cgpa, y_train_cgpa, y_test_cgpa = train_test_split(X_cgpa, y_cgpa, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting the data for placement prediction (including CGPA as a feature)\n",
    "X_placement = data.drop(['Cam_plc'], axis=1)\n",
    "y_placement = data['Cam_plc']\n",
    "\n",
    "X_train_placement, X_test_placement, y_train_placement, y_test_placement = train_test_split(X_placement, y_placement, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a27785-8a94-417b-bf71-787742dae686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the encoders and scalers on the training data only\n",
    "categorical_features = X_cgpa.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features_cgpa = X_cgpa.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numerical_features_placement = X_placement.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "scaler_cgpa = StandardScaler()\n",
    "scaler_placement = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28022e10-088d-4940-97f0-dd77d7dcb0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the target variable 'y' for both train and test sets\n",
    "y_train_placement = label_encoder.fit_transform(y_train_placement)\n",
    "y_test_placement = label_encoder.transform(y_test_placement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9ad943f-9398-41e1-9337-9f9ac33a7fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CGPA data\n",
    "X_train_categorical_cgpa = encoder.fit_transform(X_train_cgpa[categorical_features])\n",
    "X_test_categorical_cgpa = encoder.transform(X_test_cgpa[categorical_features])\n",
    "\n",
    "X_train_numerical_cgpa = scaler_cgpa.fit_transform(X_train_cgpa[numerical_features_cgpa])\n",
    "X_test_numerical_cgpa = scaler_cgpa.transform(X_test_cgpa[numerical_features_cgpa])\n",
    "\n",
    "X_train_processed_cgpa = pd.concat([pd.DataFrame(X_train_categorical_cgpa, columns=encoder.get_feature_names_out(categorical_features)),\n",
    "                                    pd.DataFrame(X_train_numerical_cgpa, columns=numerical_features_cgpa)], axis=1)\n",
    "X_test_processed_cgpa = pd.concat([pd.DataFrame(X_test_categorical_cgpa, columns=encoder.get_feature_names_out(categorical_features)),\n",
    "                                   pd.DataFrame(X_test_numerical_cgpa, columns=numerical_features_cgpa)], axis=1)\n",
    "\n",
    "# Process Placement data\n",
    "X_train_categorical_placement = encoder.transform(X_train_placement[categorical_features])\n",
    "X_test_categorical_placement = encoder.transform(X_test_placement[categorical_features])\n",
    "\n",
    "X_train_numerical_placement = scaler_placement.fit_transform(X_train_placement[numerical_features_placement])\n",
    "X_test_numerical_placement = scaler_placement.transform(X_test_placement[numerical_features_placement])\n",
    "\n",
    "X_train_processed_placement = pd.concat([pd.DataFrame(X_train_categorical_placement, columns=encoder.get_feature_names_out(categorical_features)),\n",
    "                                         pd.DataFrame(X_train_numerical_placement, columns=numerical_features_placement)], axis=1)\n",
    "X_test_processed_placement = pd.concat([pd.DataFrame(X_test_categorical_placement, columns=encoder.get_feature_names_out(categorical_features)),\n",
    "                                        pd.DataFrame(X_test_numerical_placement, columns=numerical_features_placement)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b97c2a-6570-4d56-8768-bc27dd5d165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Branch_cse  Branch_ece  Branch_ee  Branch_me  Branch_mscit  \\\n",
      "0         0.0         0.0        0.0        1.0           0.0   \n",
      "\n",
      "   Cepo _passed out  Program_mscit  C_X_B_state board  C_XII_B_state board  \\\n",
      "0               0.0            0.0                0.0                  1.0   \n",
      "\n",
      "   M_F_male  ...  End term exam SGPA - 6th semester  \\\n",
      "0       0.0  ...                           0.523461   \n",
      "\n",
      "   End term exam SGPA - 7th semester  End term exam SGPA - 8th semester  \\\n",
      "0                          -0.660108                          -0.694831   \n",
      "\n",
      "   CGPA after 8th semester  Class X grade  Class XII grade  \\\n",
      "0                 -0.77013      -0.054577         0.080749   \n",
      "\n",
      "   Overall Attendance percentage  Number of internships during undergraduate.  \\\n",
      "0                       0.166957                                     0.168771   \n",
      "\n",
      "   How many hrs you study after school?  \\\n",
      "0                              -0.71617   \n",
      "\n",
      "   How many value added program you have entered? (coursera/ AWS/IBM etc)  \n",
      "0                                          -0.758733                       \n",
      "\n",
      "[1 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_processed_placement.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b57098c4-aaed-4338-83d1-0a40e0ac311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for LSTM input\n",
    "X_train_cgpa_reshaped = np.reshape(X_train_processed_cgpa.values, (X_train_processed_cgpa.shape[0], X_train_processed_cgpa.shape[1], 1))\n",
    "X_test_cgpa_reshaped = np.reshape(X_test_processed_cgpa.values, (X_test_processed_cgpa.shape[0], X_test_processed_cgpa.shape[1], 1))\n",
    "\n",
    "X_train_placement_reshaped = np.reshape(X_train_processed_placement.values, (X_train_processed_placement.shape[0], X_train_processed_placement.shape[1], 1))\n",
    "X_test_placement_reshaped = np.reshape(X_test_processed_placement.values, (X_test_processed_placement.shape[0], X_test_processed_placement.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5e7e77-2b51-406d-accb-3f383d0c17c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model building function for CGPA prediction\n",
    "def build_model_cgpa(hp):\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(LSTM(units=hp.Int('units_' + str(i), min_value=32, max_value=128, step=32),\n",
    "                       return_sequences=True if i < hp.Int('num_layers', 1, 3) - 1 else False,\n",
    "                       input_shape=(X_train_cgpa_reshaped.shape[1], 1)))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_' + str(i), min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Define the model building function for placement prediction\n",
    "def build_model_placement(hp):\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(LSTM(units=hp.Int('units_' + str(i), min_value=32, max_value=128, step=32),\n",
    "                       return_sequences=True if i < hp.Int('num_layers', 1, 3) - 1 else False,\n",
    "                       input_shape=(X_train_placement_reshaped.shape[1], 1)))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_' + str(i), min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "603d1bac-3b4a-4b0d-bab6-c9ac94bdd430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/cgpa_tuning/tuner0.json\n",
      "Best CGPA Hyperparameters: {'num_layers': 2, 'units_0': 32, 'dropout_0': 0.2, 'units_1': 64, 'dropout_1': 0.4, 'units_2': 96, 'dropout_2': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning with Keras Tuner for CGPA prediction\n",
    "tuner_cgpa = RandomSearch(build_model_cgpa,\n",
    "                          objective='val_loss',\n",
    "                          max_trials=5,\n",
    "                          executions_per_trial=3,\n",
    "                          directory='my_dir',\n",
    "                          project_name='cgpa_tuning')\n",
    "\n",
    "tuner_cgpa.search(X_train_cgpa_reshaped, y_train_cgpa, epochs=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps_cgpa = tuner_cgpa.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f'Best CGPA Hyperparameters: {best_hps_cgpa.values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6a199a5-f4e9-4fe6-b079-89f983a58f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 15:16:49.599374: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/placement_tuning/tuner0.json\n",
      "Best Placement Hyperparameters: {'num_layers': 1, 'units_0': 128, 'dropout_0': 0.4, 'units_1': 96, 'dropout_1': 0.30000000000000004, 'units_2': 32, 'dropout_2': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning with Keras Tuner for placement prediction\n",
    "tuner_placement = RandomSearch(\n",
    "    build_model_placement,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='placement_tuning')\n",
    "\n",
    "tuner_placement.search(X_train_placement_reshaped, y_train_placement, epochs=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "# Get the optimal hyperparameters for placement prediction\n",
    "best_hps_placement = tuner_placement.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f'Best Placement Hyperparameters: {best_hps_placement.values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20ad2ae0-d52b-4ac0-91fd-51768058ef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhikrant07/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 48.3886 - val_loss: 45.1692\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 38.6726 - val_loss: 13.1377\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9.0412 - val_loss: 2.2004\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.5785 - val_loss: 1.0387\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.1307 - val_loss: 1.1623\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.9124 - val_loss: 0.8710\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.8358 - val_loss: 1.0196\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7485 - val_loss: 1.0148\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4459 - val_loss: 0.9057\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3705 - val_loss: 0.8446\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5150 - val_loss: 0.8542\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3946 - val_loss: 0.8642\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4359 - val_loss: 0.8105\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4460 - val_loss: 0.7605\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5999 - val_loss: 0.7755\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1609 - val_loss: 0.7710\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4524 - val_loss: 0.6898\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1815 - val_loss: 0.6605\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1479 - val_loss: 0.6450\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5288 - val_loss: 0.6006\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4980 - val_loss: 0.5749\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9922 - val_loss: 0.5344\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0324 - val_loss: 0.4958\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9513 - val_loss: 0.4851\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2466 - val_loss: 0.4545\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1879 - val_loss: 0.4318\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0873 - val_loss: 0.3993\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1103 - val_loss: 0.3661\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9412 - val_loss: 0.3357\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9237 - val_loss: 0.3028\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.8922 - val_loss: 0.2786\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1734 - val_loss: 0.2545\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.8237 - val_loss: 0.2473\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9727 - val_loss: 0.2627\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9646 - val_loss: 0.2585\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8468 - val_loss: 0.2566\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9163 - val_loss: 0.2515\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0732 - val_loss: 0.2358\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9445 - val_loss: 0.2295\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.8557 - val_loss: 0.2732\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.9541 - val_loss: 0.2304\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.7953 - val_loss: 0.2410\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9340 - val_loss: 0.2543\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.8507 - val_loss: 0.2354\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0235 - val_loss: 0.2393\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0165 - val_loss: 0.2274\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.7510 - val_loss: 0.2271\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8797 - val_loss: 0.2135\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0338 - val_loss: 0.2435\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.8108 - val_loss: 0.2172\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhikrant07/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.4211 - loss: 0.6975 - val_accuracy: 0.4576 - val_loss: 0.6934\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5314 - loss: 0.6930 - val_accuracy: 0.4746 - val_loss: 0.6932\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4692 - loss: 0.6931 - val_accuracy: 0.4915 - val_loss: 0.6935\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4870 - loss: 0.6929 - val_accuracy: 0.5593 - val_loss: 0.6931\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5406 - loss: 0.6905 - val_accuracy: 0.5763 - val_loss: 0.6921\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5150 - loss: 0.6882 - val_accuracy: 0.5763 - val_loss: 0.6916\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5168 - loss: 0.6910 - val_accuracy: 0.4915 - val_loss: 0.6901\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5314 - loss: 0.6940 - val_accuracy: 0.4915 - val_loss: 0.6899\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4248 - loss: 0.6951 - val_accuracy: 0.4746 - val_loss: 0.6895\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5475 - loss: 0.6900 - val_accuracy: 0.4746 - val_loss: 0.6895\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5439 - loss: 0.6938 - val_accuracy: 0.4746 - val_loss: 0.6892\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4972 - loss: 0.6917 - val_accuracy: 0.4576 - val_loss: 0.6888\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4809 - loss: 0.6964 - val_accuracy: 0.4746 - val_loss: 0.6885\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5046 - loss: 0.6917 - val_accuracy: 0.5085 - val_loss: 0.6875\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5328 - loss: 0.6865 - val_accuracy: 0.4915 - val_loss: 0.6867\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5203 - loss: 0.6939 - val_accuracy: 0.5424 - val_loss: 0.6855\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5672 - loss: 0.6898 - val_accuracy: 0.5593 - val_loss: 0.6842\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5735 - loss: 0.6870 - val_accuracy: 0.5763 - val_loss: 0.6835\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5145 - loss: 0.6872 - val_accuracy: 0.5932 - val_loss: 0.6823\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5200 - loss: 0.6906 - val_accuracy: 0.5085 - val_loss: 0.6837\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5466 - loss: 0.6853 - val_accuracy: 0.4915 - val_loss: 0.6838\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5675 - loss: 0.6942 - val_accuracy: 0.4576 - val_loss: 0.6863\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6038 - loss: 0.6789 - val_accuracy: 0.6102 - val_loss: 0.6833\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5628 - loss: 0.6890 - val_accuracy: 0.5932 - val_loss: 0.6822\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5760 - loss: 0.6858 - val_accuracy: 0.6102 - val_loss: 0.6810\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6021 - loss: 0.6758 - val_accuracy: 0.5932 - val_loss: 0.6801\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5527 - loss: 0.6823 - val_accuracy: 0.5424 - val_loss: 0.6818\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5633 - loss: 0.6801 - val_accuracy: 0.5424 - val_loss: 0.6806\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5385 - loss: 0.6878 - val_accuracy: 0.6102 - val_loss: 0.6786\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5320 - loss: 0.6885 - val_accuracy: 0.6271 - val_loss: 0.6772\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5406 - loss: 0.6846 - val_accuracy: 0.5763 - val_loss: 0.6761\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5701 - loss: 0.6843 - val_accuracy: 0.6271 - val_loss: 0.6699\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5684 - loss: 0.6842 - val_accuracy: 0.6610 - val_loss: 0.6631\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5857 - loss: 0.6780 - val_accuracy: 0.5593 - val_loss: 0.6665\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5576 - loss: 0.6661 - val_accuracy: 0.6441 - val_loss: 0.6551\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5428 - loss: 0.6735 - val_accuracy: 0.5763 - val_loss: 0.6588\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6011 - loss: 0.6537 - val_accuracy: 0.5593 - val_loss: 0.6559\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5979 - loss: 0.6586 - val_accuracy: 0.5932 - val_loss: 0.6452\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6237 - loss: 0.6486 - val_accuracy: 0.6102 - val_loss: 0.6492\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6138 - loss: 0.6449 - val_accuracy: 0.6102 - val_loss: 0.6533\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6024 - loss: 0.6641 - val_accuracy: 0.6102 - val_loss: 0.6459\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5999 - loss: 0.6468 - val_accuracy: 0.6610 - val_loss: 0.6411\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6173 - loss: 0.6624 - val_accuracy: 0.6441 - val_loss: 0.6418\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6541 - loss: 0.6442 - val_accuracy: 0.5593 - val_loss: 0.6749\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5126 - loss: 0.7028 - val_accuracy: 0.5763 - val_loss: 0.6623\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6155 - loss: 0.6474 - val_accuracy: 0.6102 - val_loss: 0.6372\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5910 - loss: 0.6614 - val_accuracy: 0.5932 - val_loss: 0.6474\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5764 - loss: 0.6672 - val_accuracy: 0.4915 - val_loss: 0.6702\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6098 - loss: 0.6569 - val_accuracy: 0.5763 - val_loss: 0.6667\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5787 - loss: 0.6706 - val_accuracy: 0.6441 - val_loss: 0.6550\n"
     ]
    }
   ],
   "source": [
    "# Build and train the final CGPA model\n",
    "model_cgpa = tuner_cgpa.hypermodel.build(best_hps_cgpa)\n",
    "epochs_cgpa = best_hps_cgpa['epochs'] if 'epochs' in best_hps_cgpa else 50  # Default to 50 if 'epochs' is not found\n",
    "history_cgpa = model_cgpa.fit(X_train_cgpa_reshaped, y_train_cgpa, epochs=epochs_cgpa, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=10)])\n",
    "\n",
    "# Build and train the final placement model\n",
    "model_placement = tuner_placement.hypermodel.build(best_hps_placement)\n",
    "epochs_placement = best_hps_placement['epochs'] if 'epochs' in best_hps_placement else 50  # Default to 50 if 'epochs' is not found\n",
    "history_placement = model_placement.fit(X_train_placement_reshaped, y_train_placement, epochs=epochs_placement, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f934a257-728d-4ee4-9476-5e3190507cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_student_cgpa(student_index):\n",
    "    # Select student data from X_cgpa\n",
    "    student_data_a = X_cgpa.iloc[student_index]\n",
    "    \n",
    "    # Convert student_data_a to NumPy array and reshape for model input\n",
    "    cgpa_input = np.array(student_data_a).reshape((1, len(student_data_a), 1))\n",
    "    \n",
    "    # Perform CGPA prediction using model_cgpa\n",
    "    predicted_cgpa = model_cgpa.predict(cgpa_input)\n",
    "    \n",
    "    # Reshape predicted_cgpa for inverse transform\n",
    "    predicted_cgpa_reshaped = predicted_cgpa.reshape((1, 1))  # Assuming a single prediction for one student\n",
    "    \n",
    "    # Inverse transform to get CGPA in original scale\n",
    "    predicted_cgpa_original = scaler_cgpa.inverse_transform(predicted_cgpa_reshaped)\n",
    "    \n",
    "    # Print the predicted CGPA in original scale\n",
    "    print('Predicted CGPA (original scale):', predicted_cgpa_original[0][0])\n",
    "\n",
    "\n",
    "\n",
    "def predict_student_placement(student_index):\n",
    "    # Select student data from X_placement\n",
    "    student_data_b = X_placement.iloc[student_index]\n",
    "    \n",
    "    # Convert student_data_b to NumPy array and reshape for model input\n",
    "    placement_input = np.array(student_data_b).reshape((1, len(student_data_b), 1))\n",
    "    \n",
    "    # Perform placement prediction using model_placement\n",
    "    predicted_placement = model_placement.predict(placement_input)\n",
    "    \n",
    "    # Define optimal_threshold for binary classification\n",
    "    optimal_threshold = 0.5\n",
    "    \n",
    "    # Print the predicted placement outcome based on the threshold\n",
    "    print('Predicted Placement:', 'Placed' if predicted_placement[0][0] > optimal_threshold else 'Not Placed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81de5515-5a58-46a7-83c0-d1311543b949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (74,1) doesn't match the broadcast shape (74,14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the models\u001b[39;00m\n\u001b[1;32m      2\u001b[0m y_pred_cgpa \u001b[38;5;241m=\u001b[39m model_cgpa\u001b[38;5;241m.\u001b[39mpredict(X_test_cgpa_reshaped)\n\u001b[0;32m----> 3\u001b[0m y_pred_cgpa_original \u001b[38;5;241m=\u001b[39m scaler_cgpa\u001b[38;5;241m.\u001b[39minverse_transform(y_pred_cgpa\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      4\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test_cgpa, y_pred_cgpa_original))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE for CGPA Prediction:\u001b[39m\u001b[38;5;124m'\u001b[39m, rmse)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:1107\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_std:\n\u001b[0;32m-> 1107\u001b[0m         X \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n\u001b[1;32m   1109\u001b[0m         X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (74,1) doesn't match the broadcast shape (74,14)"
     ]
    }
   ],
   "source": [
    "# # Evaluate the models\n",
    "# y_pred_cgpa = model_cgpa.predict(X_test_cgpa_reshaped)\n",
    "# y_pred_cgpa_original = scaler_cgpa.inverse_transform(y_pred_cgpa.reshape(-1, 1))\n",
    "# rmse = np.sqrt(mean_squared_error(y_test_cgpa, y_pred_cgpa_original))\n",
    "# print('RMSE for CGPA Prediction:', rmse)\n",
    "\n",
    "# y_pred_placement = model_placement.predict(X_test_placement_reshaped)\n",
    "# y_pred_placement_binary = (y_pred_placement > 0.5).astype(int)\n",
    "\n",
    "# accuracy = accuracy_score(y_test_placement, y_pred_placement_binary)\n",
    "# precision = precision_score(y_test_placement, y_pred_placement_binary)\n",
    "# recall = recall_score(y_test_placement, y_pred_placement_binary)\n",
    "# f1 = f1_score(y_test_placement, y_pred_placement_binary)\n",
    "\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "# print(f'Precision: {precision}')\n",
    "# print(f'Recall: {recall}')\n",
    "# print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e73fd128-280c-4142-9896-92af1c9682ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhikrant07/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 43.8375 - val_loss: 3.5244\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.3798 - val_loss: 1.4185\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.9566 - val_loss: 1.1622\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.4370 - val_loss: 0.9620\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.4805 - val_loss: 0.9933\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.4390 - val_loss: 0.9074\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.2690 - val_loss: 0.8823\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.3736 - val_loss: 0.8294\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.2206 - val_loss: 0.7715\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.2611 - val_loss: 0.8889\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.3398 - val_loss: 0.7580\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.0391 - val_loss: 0.6160\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.2036 - val_loss: 0.5793\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.0819 - val_loss: 0.5969\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.1542 - val_loss: 0.4897\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.9051 - val_loss: 0.4414\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.0107 - val_loss: 0.3435\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.9097 - val_loss: 0.3730\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.9714 - val_loss: 0.2750\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7851 - val_loss: 0.1948\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.7587 - val_loss: 0.2726\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.9567 - val_loss: 0.1871\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.7603 - val_loss: 0.1592\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6804 - val_loss: 0.2605\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.8246 - val_loss: 0.1556\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.8256 - val_loss: 0.2002\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.7184 - val_loss: 0.1848\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6504 - val_loss: 0.2092\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.7755 - val_loss: 0.2516\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6706 - val_loss: 0.1382\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7876 - val_loss: 0.1662\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7231 - val_loss: 0.2096\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6717 - val_loss: 0.1378\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5683 - val_loss: 0.1856\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.7450 - val_loss: 0.1755\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6239 - val_loss: 0.1518\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.7494 - val_loss: 0.1687\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6841 - val_loss: 0.2039\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6623 - val_loss: 0.1674\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6243 - val_loss: 0.2605\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6752 - val_loss: 0.2525\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6351 - val_loss: 0.2061\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6444 - val_loss: 0.1663\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6353 - val_loss: 0.1618\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6952 - val_loss: 0.1358\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.7676 - val_loss: 0.1492\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.5511 - val_loss: 0.1602\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5967 - val_loss: 0.1463\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5564 - val_loss: 0.1537\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.5936 - val_loss: 0.1342\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6480 - val_loss: 0.1481\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6285 - val_loss: 0.1306\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6219 - val_loss: 0.1489\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.7423 - val_loss: 0.1704\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6571 - val_loss: 0.1146\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6166 - val_loss: 0.2175\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.7202 - val_loss: 0.2176\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.6860 - val_loss: 0.1592\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.5809 - val_loss: 0.2422\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6747 - val_loss: 0.1809\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5801 - val_loss: 0.1578\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.6395 - val_loss: 0.1213\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.7060 - val_loss: 0.1410\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5081 - val_loss: 0.1493\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7012 - val_loss: 0.2463\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.6096 - val_loss: 0.1834\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.6385 - val_loss: 0.1531\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5702 - val_loss: 0.1411\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.7232 - val_loss: 0.1202\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5436 - val_loss: 0.0936\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5493 - val_loss: 0.1059\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.6377 - val_loss: 0.1337\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5610 - val_loss: 0.1275\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6402 - val_loss: 0.1290\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.6122 - val_loss: 0.1105\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5457 - val_loss: 0.1174\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.6613 - val_loss: 0.1111\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4675 - val_loss: 0.1080\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.5316 - val_loss: 0.1535\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5522 - val_loss: 0.1303\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.4263 - val_loss: 0.1419\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.6087 - val_loss: 0.1383\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.6152 - val_loss: 0.1963\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6320 - val_loss: 0.1423\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.6014 - val_loss: 0.1255\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4948 - val_loss: 0.2056\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6286 - val_loss: 0.1521\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.5106 - val_loss: 0.1335\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4757 - val_loss: 0.1263\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4983 - val_loss: 0.1726\n",
      "X_test_cgpa_reshaped shape: (74, 34, 1)\n",
      "y_test_cgpa shape: (74,)\n",
      "Evaluation result: 0.17261579632759094\n",
      "MSE for CGPA: 0.17261579632759094\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhikrant07/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.4852 - loss: 0.6930 - val_accuracy: 0.4595 - val_loss: 0.6980\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4696 - loss: 0.6954 - val_accuracy: 0.4054 - val_loss: 0.7004\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4761 - loss: 0.6933 - val_accuracy: 0.3784 - val_loss: 0.7025\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4792 - loss: 0.6920 - val_accuracy: 0.4595 - val_loss: 0.6975\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5124 - loss: 0.6922 - val_accuracy: 0.4595 - val_loss: 0.6984\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5461 - loss: 0.6895 - val_accuracy: 0.4459 - val_loss: 0.6966\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4948 - loss: 0.6936 - val_accuracy: 0.3378 - val_loss: 0.7011\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5346 - loss: 0.6908 - val_accuracy: 0.4189 - val_loss: 0.6983\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5178 - loss: 0.6926 - val_accuracy: 0.4189 - val_loss: 0.6990\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5295 - loss: 0.6897 - val_accuracy: 0.5000 - val_loss: 0.6952\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5784 - loss: 0.6885 - val_accuracy: 0.4324 - val_loss: 0.6970\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4851 - loss: 0.6911 - val_accuracy: 0.5135 - val_loss: 0.6928\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5718 - loss: 0.6871 - val_accuracy: 0.6216 - val_loss: 0.6852\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5262 - loss: 0.6895 - val_accuracy: 0.6757 - val_loss: 0.6808\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5355 - loss: 0.6867 - val_accuracy: 0.5676 - val_loss: 0.6865\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5717 - loss: 0.6857 - val_accuracy: 0.5676 - val_loss: 0.6815\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5395 - loss: 0.6842 - val_accuracy: 0.5135 - val_loss: 0.6973\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5345 - loss: 0.6814 - val_accuracy: 0.4865 - val_loss: 0.6991\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5145 - loss: 0.6890 - val_accuracy: 0.6486 - val_loss: 0.6705\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5510 - loss: 0.6866 - val_accuracy: 0.6486 - val_loss: 0.6733\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5480 - loss: 0.6856 - val_accuracy: 0.5946 - val_loss: 0.6747\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5733 - loss: 0.6748 - val_accuracy: 0.6216 - val_loss: 0.6674\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5397 - loss: 0.6811 - val_accuracy: 0.5541 - val_loss: 0.6685\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5441 - loss: 0.6739 - val_accuracy: 0.5541 - val_loss: 0.6907\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5833 - loss: 0.6668 - val_accuracy: 0.5676 - val_loss: 0.6754\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5794 - loss: 0.6662 - val_accuracy: 0.5541 - val_loss: 0.6796\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5757 - loss: 0.6635 - val_accuracy: 0.5676 - val_loss: 0.6705\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5280 - loss: 0.6696 - val_accuracy: 0.5811 - val_loss: 0.6589\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5966 - loss: 0.6584 - val_accuracy: 0.5270 - val_loss: 0.6807\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5901 - loss: 0.6582 - val_accuracy: 0.5946 - val_loss: 0.6646\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5827 - loss: 0.6633 - val_accuracy: 0.4459 - val_loss: 0.7034\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5897 - loss: 0.6588 - val_accuracy: 0.6216 - val_loss: 0.6410\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5819 - loss: 0.6428 - val_accuracy: 0.5541 - val_loss: 0.6486\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5899 - loss: 0.6463 - val_accuracy: 0.5946 - val_loss: 0.6484\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5567 - loss: 0.6442 - val_accuracy: 0.5676 - val_loss: 0.6462\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5856 - loss: 0.6379 - val_accuracy: 0.5541 - val_loss: 0.6692\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6412 - loss: 0.6417 - val_accuracy: 0.5676 - val_loss: 0.6761\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5909 - loss: 0.6588 - val_accuracy: 0.5676 - val_loss: 0.6656\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6398 - loss: 0.6414 - val_accuracy: 0.5541 - val_loss: 0.6686\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6337 - loss: 0.6378 - val_accuracy: 0.4865 - val_loss: 0.6637\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6319 - loss: 0.6266 - val_accuracy: 0.5676 - val_loss: 0.6624\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6416 - loss: 0.6442 - val_accuracy: 0.5405 - val_loss: 0.6448\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6659 - loss: 0.6158 - val_accuracy: 0.5135 - val_loss: 0.6998\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6719 - loss: 0.6230 - val_accuracy: 0.5676 - val_loss: 0.6560\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6882 - loss: 0.6145 - val_accuracy: 0.5541 - val_loss: 0.6670\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6330 - loss: 0.6393 - val_accuracy: 0.5270 - val_loss: 0.6729\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6805 - loss: 0.6179 - val_accuracy: 0.5676 - val_loss: 0.6497\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6558 - loss: 0.6110 - val_accuracy: 0.5811 - val_loss: 0.6410\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6986 - loss: 0.5686 - val_accuracy: 0.5000 - val_loss: 0.6994\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6322 - loss: 0.6297 - val_accuracy: 0.5676 - val_loss: 0.6415\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6393 - loss: 0.6229 - val_accuracy: 0.5541 - val_loss: 0.6549\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6415 - loss: 0.6239 - val_accuracy: 0.5541 - val_loss: 0.6398\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6976 - loss: 0.6053 - val_accuracy: 0.5405 - val_loss: 0.6392\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6793 - loss: 0.6125 - val_accuracy: 0.5811 - val_loss: 0.6526\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7191 - loss: 0.5933 - val_accuracy: 0.5811 - val_loss: 0.6513\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6670 - loss: 0.6008 - val_accuracy: 0.5676 - val_loss: 0.6698\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7175 - loss: 0.5752 - val_accuracy: 0.5541 - val_loss: 0.6506\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6687 - loss: 0.5869 - val_accuracy: 0.5946 - val_loss: 0.6806\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6601 - loss: 0.6018 - val_accuracy: 0.5676 - val_loss: 0.6324\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6950 - loss: 0.5730 - val_accuracy: 0.5676 - val_loss: 0.6478\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6975 - loss: 0.5758 - val_accuracy: 0.5135 - val_loss: 0.6538\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7074 - loss: 0.5596 - val_accuracy: 0.5541 - val_loss: 0.6296\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7125 - loss: 0.5607 - val_accuracy: 0.5541 - val_loss: 0.6623\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7350 - loss: 0.5411 - val_accuracy: 0.5405 - val_loss: 0.6549\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7282 - loss: 0.5495 - val_accuracy: 0.5405 - val_loss: 0.6374\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6714 - loss: 0.5806 - val_accuracy: 0.5946 - val_loss: 0.7099\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6832 - loss: 0.5635 - val_accuracy: 0.5135 - val_loss: 0.6711\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7343 - loss: 0.5514 - val_accuracy: 0.5811 - val_loss: 0.6247\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7817 - loss: 0.5236 - val_accuracy: 0.5811 - val_loss: 0.6525\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7521 - loss: 0.5187 - val_accuracy: 0.5135 - val_loss: 0.6673\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7662 - loss: 0.5192 - val_accuracy: 0.5946 - val_loss: 0.6481\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7109 - loss: 0.5250 - val_accuracy: 0.5676 - val_loss: 0.6401\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7470 - loss: 0.4997 - val_accuracy: 0.6757 - val_loss: 0.5894\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7520 - loss: 0.4979 - val_accuracy: 0.6486 - val_loss: 0.6049\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7250 - loss: 0.5207 - val_accuracy: 0.6081 - val_loss: 0.6458\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7516 - loss: 0.5257 - val_accuracy: 0.6216 - val_loss: 0.6280\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7427 - loss: 0.5045 - val_accuracy: 0.6081 - val_loss: 0.6357\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7499 - loss: 0.5117 - val_accuracy: 0.6216 - val_loss: 0.6246\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7790 - loss: 0.4605 - val_accuracy: 0.6081 - val_loss: 0.6443\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7893 - loss: 0.4497 - val_accuracy: 0.6486 - val_loss: 0.6191\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7443 - loss: 0.4847 - val_accuracy: 0.6622 - val_loss: 0.5946\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7380 - loss: 0.5027 - val_accuracy: 0.5946 - val_loss: 0.6400\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8241 - loss: 0.4435 - val_accuracy: 0.6216 - val_loss: 0.6054\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8163 - loss: 0.4346 - val_accuracy: 0.6081 - val_loss: 0.5919\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7341 - loss: 0.4827 - val_accuracy: 0.5676 - val_loss: 0.6639\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7647 - loss: 0.4766 - val_accuracy: 0.5811 - val_loss: 0.6135\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7573 - loss: 0.4592 - val_accuracy: 0.5946 - val_loss: 0.6194\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7586 - loss: 0.4829 - val_accuracy: 0.5946 - val_loss: 0.6289\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7946 - loss: 0.4137 - val_accuracy: 0.5541 - val_loss: 0.6500\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7890 - loss: 0.4354 - val_accuracy: 0.5811 - val_loss: 0.6097\n",
      "Accuracy for Placement: 0.5810810923576355\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Assuming you have imported necessary libraries and defined tuner_cgpa, tuner_placement, X_train_cgpa_reshaped, y_train_cgpa, X_test_cgpa_reshaped, y_test_cgpa, X_train_placement_reshaped, y_train_placement, X_test_placement_reshaped, y_test_placement correctly\n",
    "\n",
    "# Load the best hyperparameters for CGPA prediction\n",
    "with open('best_hps_cgpa.pkl', 'rb') as f:\n",
    "    best_hps_cgpa = pickle.load(f)\n",
    "\n",
    "# Build and train the CGPA prediction model using the best hyperparameters\n",
    "model_cgpa = tuner_cgpa.hypermodel.build(best_hps_cgpa)\n",
    "model_cgpa.fit(X_train_cgpa_reshaped, y_train_cgpa, epochs=100, initial_epoch=10, validation_data=(X_test_cgpa_reshaped, y_test_cgpa))\n",
    "# Assuming model_cgpa is defined and compiled correctly\n",
    "\n",
    "# Print the shapes of X_test_cgpa_reshaped and y_test_cgpa\n",
    "print('X_test_cgpa_reshaped shape:', X_test_cgpa_reshaped.shape)\n",
    "print('y_test_cgpa shape:', y_test_cgpa.shape)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_result = model_cgpa.evaluate(X_test_cgpa_reshaped, y_test_cgpa, verbose=0)\n",
    "print('Evaluation result:', evaluation_result)\n",
    "\n",
    "# Assuming evaluation_result is a float, you can access the MSE directly\n",
    "mse_cgpa = evaluation_result\n",
    "print('MSE for CGPA:', mse_cgpa)\n",
    "\n",
    "# Load the best hyperparameters for placement prediction\n",
    "with open('best_hps_placement.pkl', 'rb') as f:\n",
    "    best_hps_placement = pickle.load(f)\n",
    "\n",
    "# Build and train the placement prediction model using the best hyperparameters\n",
    "model_placement = tuner_placement.hypermodel.build(best_hps_placement)\n",
    "model_placement.fit(X_train_placement_reshaped, y_train_placement, epochs=100, initial_epoch=10, validation_data=(X_test_placement_reshaped, y_test_placement))\n",
    "loss_placement, acc_placement = model_placement.evaluate(X_test_placement_reshaped, y_test_placement, verbose=0)\n",
    "print('Accuracy for Placement:', acc_placement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0da1bf82-1819-46ca-a915-bf4e7fc5b274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_processed_cgpa shape: (74, 34)\n",
      "X_test_processed_placement shape: (74, 35)\n",
      "9.13\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.float64).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test_processed_placement shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, X_test_processed_placement\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m10\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCGPA after 8th semester\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m predict_student_cgpa(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m10\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCam_plc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m predict_student_placement(\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m, in \u001b[0;36mpredict_student_cgpa\u001b[0;34m(student_index)\u001b[0m\n\u001b[1;32m      6\u001b[0m cgpa_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(student_data_a)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(student_data_a), \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Perform CGPA prediction using model_cgpa\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m predicted_cgpa \u001b[38;5;241m=\u001b[39m model_cgpa\u001b[38;5;241m.\u001b[39mpredict(cgpa_input)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Reshape predicted_cgpa for inverse transform\u001b[39;00m\n\u001b[1;32m     12\u001b[0m predicted_cgpa_reshaped \u001b[38;5;241m=\u001b[39m predicted_cgpa\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Assuming a single prediction for one student\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.float64)."
     ]
    }
   ],
   "source": [
    "# Example of how to debug the index error\n",
    "print('X_test_processed_cgpa shape:', X_test_processed_cgpa.shape)\n",
    "print('X_test_processed_placement shape:', X_test_processed_placement.shape)\n",
    "\n",
    "print(data.iloc[10]['CGPA after 8th semester'])\n",
    "predict_student_cgpa(10)\n",
    "print(data.iloc[10]['Cam_plc'])\n",
    "predict_student_placement(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e2c75-e1d0-48f1-84e6-642fb92bfffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8791d4b-7b64-408f-aed6-1f4d43c1e870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
